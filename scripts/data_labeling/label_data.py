import pandas as pd
import re
from transformers import AutoTokenizer
import random
import logging

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')

# Load data
data = pd.read_csv('data/raw/telegram_data.csv')
messages = data['Message'].dropna().sample(n=50, random_state=42).tolist()

# Expanded rule-based labeling
labeled_data = []
location_keywords = ['áŠ á‹²áˆµ', 'á‰¦áˆŒ', 'á’á‹«áˆ³', 'áˆ˜áŒˆáŠ“áŠ›', 'áˆœáŠ­áˆ²áŠ®', 'áŒ‰áˆ­á‹µ', 'áˆ¾áˆ‹', 'áˆ†áˆŠ', 'áˆ²á‰²', 'áˆ´áŠ•á‰°áˆ­', 'á‹µáˆ¬á‹³á‹‹', 'áŒˆáˆ­áŒ‚', '4áŠªáˆŽ', '5áŠªáˆŽ', '6áŠªáˆŽ', 'ðŸ¢áŠ á‹µáˆ«áˆ»-áˆœáŠ­áˆ²áŠ®']
location_i_keywords = ['áŠ á‰ á‰£', '3áŠ›', 'áŽá‰…', 'áŠ áˆ¸á‹‹', 'áˆšáŠ“', 'áŠ®áˆœáˆ­áˆµ', 'áŒ€áˆ­á‰£', 'áˆ˜á‹šá‹µ', 'á•áˆ‹á‹›', 'áŠ¢áˆá”áˆªá‹«áˆ', 'áŠ¨áˆ³áˆš', 'áˆ…áŠ•áƒ', 'áŒŽáŠ•', 'áŠ áˆáŽá‹', 'á•áˆ‹á‹›', 'áŒáˆ«á‹áŠ•á‹µ', 'á‰…á‹µáˆµá‰µ', 'áˆµáˆ‹áˆ´', 'áˆ…áŠ•áƒ']
product_keywords = ['áŒ«áˆ›', 'áˆá‰¥áˆµ', 'áˆµáˆáŠ­', 'á‰¦áˆ­áˆ³', 'á‰²áˆ¸áˆ­á‰µ', 'áŒƒáŠ¬á‰µ', 'áˆ˜á‰°áŠ®áˆ»', 'áˆ›á‰ áŒ áˆªá‹«', 'á”áˆµá‰µáˆ«', 'áˆ˜áŠªáŠŠáŠ“', 'BMW', 'á‰ áŒáˆ«áˆªáŠ“', 'á‰ á–áˆ­áˆ½', 'áˆ˜áŠªáŠ“', 'áˆµáŒ¦á‰³', 'áˆµáˆáŠ­', 'áˆµá‹•áˆ', 'á‹°á‰¥á‰°áˆ­']
price_keywords = ['á‰¥áˆ­', 'áˆº', 'áˆ˜á‰¶']
price_context = ['á‹‹áŒ‹', 'á‰¥áˆ­']
phone_context = ['á‹­á‹°á‹áˆ‰', 'á‰áŒ¥áˆ­']
product_context = ['á‰ ', 'á‹¨', '#áˆµáŒ¦á‰³']
stop_words = ['á‹­áˆáŒ¡', 'á‹­á‹°á‹áˆ‰', 'http', 'T.me', 'tiktok', 'facebook', '@', '#']

for message in messages:
    tokens = message.split()  # Whitespace tokenization
    labels = []
    in_location = False  # Track multi-word locations
    location_count = 0  # Limit location length
    for i, token in enumerate(tokens):
        # Stop location tagging if too long or stop word encountered
        if in_location and (location_count > 5 or token in stop_words):
            in_location = False
            location_count = 0
        # Handle addresses
        if token == 'áŠ á‹µáˆ«áˆ»á¦':
            labels.append('O')
            in_location = True
            location_count = 0
            logging.info(f"Started location at token: {token}")
            continue
        elif in_location and token not in ['.', ',', '1.', '2.']:
            labels.append('B-LOC' if not labels or labels[-1] not in ['B-LOC', 'I-LOC'] else 'I-LOC')
            location_count += 1
            logging.info(f"Labeled {token} as {'B-LOC' if not labels or labels[-1] not in ['B-LOC', 'I-LOC'] else 'I-LOC'}")
            continue
        # Handle phone numbers
        elif re.match(r'^\d+$', token) and len(token) >= 9 and (i > 0 and tokens[i-1] in phone_context):
            labels.append('O')
            in_location = False
            logging.info(f"Labeled {token} as O (phone number)")
            continue
        # Handle prices
        elif any(kw in token for kw in price_keywords) or (re.match(r'^\d+$', token) and len(token) <= 6 and
            (i > 0 and tokens[i-1] in price_context or (i < len(tokens)-1 and tokens[i+1] in price_context))):
            labels.append('B-PRICE' if not labels or labels[-1] not in ['B-PRICE', 'I-PRICE'] else 'I-PRICE')
            in_location = False
            logging.info(f"Labeled {token} as {'B-PRICE' if not labels or labels[-1] not in ['B-PRICE', 'I-PRICE'] else 'I-PRICE'}")
            continue
        # Handle products
        elif token in product_keywords or (token.startswith('#') and any(kw in token for kw in ['BMW', 'á‰ áŒáˆ«áˆªáŠ“', 'á‰ á–áˆ­áˆ½', 'áˆ˜áŠªáŠ“'])):
            labels.append('B-Product')
            in_location = False
            logging.info(f"Labeled {token} as B-Product")
        elif i > 0 and labels[i-1] in ['B-Product', 'I-Product'] and (token.startswith('á‹¨') or token in product_context):
            labels.append('I-Product')
            in_location = False
            logging.info(f"Labeled {token} as I-Product")
        # Handle locations
        elif token in location_keywords:
            labels.append('B-LOC')
            in_location = False
            logging.info(f"Labeled {token} as B-LOC")
        elif token in location_i_keywords and i > 0 and labels[i-1] in ['B-LOC', 'I-LOC']:
            labels.append('I-LOC')
            in_location = False
            logging.info(f"Labeled {token} as I-LOC")
        else:
            labels.append('O')
            in_location = False
            logging.info(f"Labeled {token} as O")
    labeled_data.append(list(zip(tokens, labels)))

# Save to CoNLL format
with open('data/processed/labeled_data.conll', 'w', encoding='utf-8') as f:
    for sentence in labeled_data:
        for token, label in sentence:
            f.write(f"{token} {label}\n")
        f.write("\n")

# Save to CSV for manual review
review_data = []
for i, sentence in enumerate(labeled_data):
    for token, label in sentence:
        review_data.append({'Sentence': i, 'Token': token, 'Label': label})
pd.DataFrame(review_data).to_csv('data/processed/labeled_data_review.csv', encoding='utf-8', index=False)

# Print sample for validation
print("Sample Labeled Messages:")
for sentence in labeled_data[:3]:
    for token, label in sentence:
        print(f"{token} {label}")
    print()